{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vanna.openai import OpenAI_Chat\n",
    "from vanna.chromadb import ChromaDB_VectorStore\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Configuration Langfuse pour le monitoring\n",
    "from langfuse.openai import openai\n",
    "from langfuse import Langfuse\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration des cl√©s Langfuse\n",
    "langfuse = Langfuse(\n",
    "    public_key=os.getenv('LANGFUSE_PUBLIC_KEY'),\n",
    "    secret_key=os.getenv('LANGFUSE_SECRET_KEY'),\n",
    "    host=os.getenv('LANGFUSE_HOST', 'https://cloud.langfuse.com')\n",
    ")\n",
    "\n",
    "class MyVanna(ChromaDB_VectorStore, OpenAI_Chat):\n",
    "    def __init__(self, config=None):\n",
    "        ChromaDB_VectorStore.__init__(self, config=config)\n",
    "        OpenAI_Chat.__init__(self, config=config)\n",
    "        \n",
    "        # Remplacer le client OpenAI par la version instrument√©e Langfuse\n",
    "        import openai as openai_original\n",
    "        if hasattr(self, '_client'):\n",
    "            # Sauvegarder la cl√© API\n",
    "            api_key = getattr(self._client, 'api_key', config.get('api_key'))\n",
    "            # Remplacer par le client Langfuse\n",
    "            self._client = openai.OpenAI(api_key=api_key)\n",
    "    \n",
    "    def submit_prompt(self, prompt, **kwargs):\n",
    "        \"\"\"Override pour ajouter le tracking Langfuse\"\"\"\n",
    "        with langfuse.trace(\n",
    "            name=\"vanna-query\",\n",
    "            input={\"prompt\": prompt, \"kwargs\": kwargs},\n",
    "            user_id=kwargs.get('user_id', 'anonymous'),\n",
    "            session_id=kwargs.get('session_id', 'default'),\n",
    "            tags=[\"vanna\", \"sql-generation\"]\n",
    "        ) as trace:\n",
    "            try:\n",
    "                result = super().submit_prompt(prompt, **kwargs)\n",
    "                trace.update(output={\"result\": result})\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                trace.update(output={\"error\": str(e)})\n",
    "                raise\n",
    "\n",
    "vn = MyVanna(config={'api_key':os.getenv('OPENAI_API_KEY'), 'model': 'gpt-4o-mini'})\n",
    "# vn.remove_training_data()\n",
    "\n",
    "vn.connect_to_postgres(host=os.getenv('POSTGRES_HOST'), dbname=os.getenv('POSTGRES_DB'), user=os.getenv('POSTGRES_USER'), password=os.getenv('POSTGRES_PASSWORD'), port=os.getenv('POSTGRES_PORT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your app is running at:\n",
      "http://localhost:8084\n",
      " * Serving Flask app 'vanna.flask'\n",
      " * Debug mode: on\n",
      "Using model gpt-4o-mini for 4746.25 tokens (approx)\n",
      "Using model gpt-4o-mini for 102.75 tokens (approx)\n"
     ]
    }
   ],
   "source": [
    "# Ajout du monitoring personnalis√© pour l'application Flask\n",
    "import functools\n",
    "from flask import request\n",
    "\n",
    "def track_flask_requests(app_instance):\n",
    "    \"\"\"D√©corateur pour tracker les requ√™tes Flask avec Langfuse\"\"\"\n",
    "    original_ask = app_instance.vn.ask\n",
    "    \n",
    "    @functools.wraps(original_ask)\n",
    "    def tracked_ask(question, **kwargs):\n",
    "        # R√©cup√©rer les informations de la requ√™te\n",
    "        session_id = request.session.get('session_id', 'flask-session')\n",
    "        user_id = request.remote_addr  # IP comme ID utilisateur basique\n",
    "        \n",
    "        with langfuse.trace(\n",
    "            name=\"vanna-flask-ask\",\n",
    "            input={\"question\": question, \"kwargs\": kwargs},\n",
    "            user_id=user_id,\n",
    "            session_id=session_id,\n",
    "            tags=[\"vanna\", \"flask\", \"text-to-sql\"],\n",
    "            metadata={\n",
    "                \"user_agent\": request.headers.get('User-Agent'),\n",
    "                \"method\": request.method,\n",
    "                \"endpoint\": request.endpoint\n",
    "            }\n",
    "        ) as trace:\n",
    "            try:\n",
    "                # Mesurer la latence\n",
    "                import time\n",
    "                start_time = time.time()\n",
    "                \n",
    "                result = original_ask(question, **kwargs)\n",
    "                \n",
    "                end_time = time.time()\n",
    "                latency_ms = (end_time - start_time) * 1000\n",
    "                \n",
    "                trace.update(\n",
    "                    output={\"result\": result},\n",
    "                    metadata={\"latency_ms\": latency_ms}\n",
    "                )\n",
    "                \n",
    "                # Enregistrer les m√©triques de co√ªt si disponibles\n",
    "                if hasattr(result, 'usage'):\n",
    "                    trace.update(\n",
    "                        usage={\n",
    "                            \"input_tokens\": getattr(result.usage, 'prompt_tokens', 0),\n",
    "                            \"output_tokens\": getattr(result.usage, 'completion_tokens', 0),\n",
    "                            \"total_tokens\": getattr(result.usage, 'total_tokens', 0)\n",
    "                        }\n",
    "                    )\n",
    "                \n",
    "                return result\n",
    "            except Exception as e:\n",
    "                trace.update(\n",
    "                    output={\"error\": str(e)},\n",
    "                    level=\"ERROR\"\n",
    "                )\n",
    "                raise\n",
    "    \n",
    "    app_instance.vn.ask = tracked_ask\n",
    "    return app_instance\n",
    "\n",
    "from vanna.flask import VannaFlaskApp\n",
    "\n",
    "# Cr√©er l'application Flask avec monitoring\n",
    "flask_app = VannaFlaskApp(vn, allow_llm_to_see_data=True)\n",
    "\n",
    "# Appliquer le tracking Langfuse\n",
    "flask_app = track_flask_requests(flask_app)\n",
    "\n",
    "print(\"üîç Langfuse monitoring activ√©!\")\n",
    "print(f\"üìä Dashboard: {os.getenv('LANGFUSE_HOST', 'https://cloud.langfuse.com')}\")\n",
    "print(\"üöÄ Toutes les requ√™tes seront track√©es automatiquement...\")\n",
    "\n",
    "# Lancer l'application\n",
    "flask_app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
